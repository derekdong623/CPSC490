{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import csv\n",
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "START_DIR = Path(os.getcwd()).parent.resolve()\n",
    "def get_dir(run_bun=False):\n",
    "    dir = os.path.join(START_DIR, \"data\")\n",
    "    return os.path.join(dir, \"run_and_bun\" if run_bun else \"base_gen_8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enums"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Types: 0-indexed in enum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL_TYPES = [\n",
    "    \"NORMAL\",\n",
    "    \"FIRE\",\n",
    "    \"WATER\",\n",
    "    \"ELECTRIC\",\n",
    "    \"GRASS\",\n",
    "    \"ICE\",\n",
    "    \"FIGHTING\",\n",
    "    \"POISON\",\n",
    "    \"GROUND\",\n",
    "    \"FLYING\",\n",
    "    \"PSYCHIC\",\n",
    "    \"BUG\",\n",
    "    \"ROCK\",\n",
    "    \"GHOST\",\n",
    "    \"DRAGON\",\n",
    "    \"DARK\",\n",
    "    \"STEEL\",\n",
    "    \"FAIRY\",\n",
    "    \"\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL_MOVE_KINDS = [None, \"SPECIAL\", \"STATUS\", \"PHYSICAL\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "UNAVAILABLE_PKMN = [\n",
    "  \"Caterpie\",\n",
    "  \"Metapod \",\n",
    "  \"Butterfree\",\n",
    "  \"Rattata\",\n",
    "  \"Raticate\",\n",
    "  \"Spearow\",\n",
    "  \"Fearow\",\n",
    "  \"Sandshrew\",\n",
    "  \"Sandslash\",\n",
    "  \"Vulpix\",\n",
    "  \"Ninetales\",\n",
    "  \"Jigglypuff\",\n",
    "  \"Wigglytuff\",\n",
    "  \"Venonat\",\n",
    "  \"Venomoth\",\n",
    "  \"Diglett\",\n",
    "  \"Dugtrio\",\n",
    "  \"Meowth\",\n",
    "  \"Persian\",\n",
    "  \"Mankey\",\n",
    "  \"Primeape\",\n",
    "  \"Poliwag\",\n",
    "  \"Poliwhirl\",\n",
    "  \"Poliwrath\",\n",
    "  \"Machop\",\n",
    "  \"Machoke\",\n",
    "  \"Machamp\",\n",
    "  \"Geodude\",\n",
    "  \"Graveler\",\n",
    "  \"Golem\",\n",
    "  \"Farfetch'd\",\n",
    "  \"Doduo\",\n",
    "  \"Dodrio\",\n",
    "  \"Seel\",\n",
    "  \"Dewgong\",\n",
    "  \"Grimer\",\n",
    "  \"Muk\",\n",
    "  \"Voltorb\",\n",
    "  \"Electrode\",\n",
    "  \"Cubone\",\n",
    "  \"Marowak\",\n",
    "  \"Lickitung\",\n",
    "  \"Chansey\",\n",
    "  \"Tangela\",\n",
    "  \"Goldeen\",\n",
    "  \"Seaking\",\n",
    "  \"Mr. Mime\",\n",
    "  \"Lapras\",\n",
    "  \"Ditto\",\n",
    "  \"Eevee\",\n",
    "  \"Vaporeon\",\n",
    "  \"Jolteon\",\n",
    "  \"Flareon\",\n",
    "  \"Snorlax\",\n",
    "  \"Articuno\",\n",
    "  \"Zapdos\",\n",
    "  \"Moltres\",\n",
    "  \"Mewtwo,Sentret\",\n",
    "  \"Furret\",\n",
    "  \"Hoothoot\",\n",
    "  \"Noctowl\",\n",
    "  \"Spinarak\",\n",
    "  \"Ariados\",\n",
    "  \"Igglybuff\",\n",
    "  \"Politoed\",\n",
    "  \"Hoppip\",\n",
    "  \"Skiploom\",\n",
    "  \"Jumpluff\",\n",
    "  \"Sunkern\",\n",
    "  \"Sunflora\",\n",
    "  \"Wooper\",\n",
    "  \"Quagsire\",\n",
    "  \"Espeon\",\n",
    "  \"Umbreon\",\n",
    "  \"Misdreavus\",\n",
    "  \"Unown\",\n",
    "  \"Wobbuffet\",\n",
    "  \"Girafarig\",\n",
    "  \"Pineco\",\n",
    "  \"Forretress\",\n",
    "  \"Dunsparce\",\n",
    "  \"Shuckle\",\n",
    "  \"Slugma\",\n",
    "  \"Magcargo\",\n",
    "  \"Corsola\",\n",
    "  \"Delibird\",\n",
    "  \"Mantine\",\n",
    "  \"Skarmory\",\n",
    "  \"Smeargle\",\n",
    "  \"Blissey\",\n",
    "  \"Raikou\",\n",
    "  \"Entei\",\n",
    "  \"Suicune\",\n",
    "  \"Lugia\",\n",
    "  \"Ho-Oh,Zigzagoon\",\n",
    "  \"Linoone\",\n",
    "  \"Wurmple\",\n",
    "  \"Silcoon\",\n",
    "  \"Beautifly\",\n",
    "  \"Cascoon\",\n",
    "  \"Dustox\",\n",
    "  \"Nincada\",\n",
    "  \"Ninjask\",\n",
    "  \"Shedinja\",\n",
    "  \"Taillow\",\n",
    "  \"Swellow\",\n",
    "  \"Spinda\",\n",
    "  \"Wingull\",\n",
    "  \"Pelipper\",\n",
    "  \"Barboach\",\n",
    "  \"Whiscash\",\n",
    "  \"Luvdisc\",\n",
    "  \"Cacnea\",\n",
    "  \"Cacturne\",\n",
    "  \"Lunatone\",\n",
    "  \"Solrock\",\n",
    "  \"Spoink\",\n",
    "  \"Grumpig\",\n",
    "  \"Plusle\",\n",
    "  \"Minun\",\n",
    "  \"Wynaut\",\n",
    "  \"Duskull\",\n",
    "  \"Dusclops\",\n",
    "  \"Slakoth\",\n",
    "  \"Vigoroth\",\n",
    "  \"Slaking\",\n",
    "  \"Gulpin\",\n",
    "  \"Swalot\",\n",
    "  \"Tropius\",\n",
    "  \"Whismur\",\n",
    "  \"Loudred\",\n",
    "  \"Exploud\",\n",
    "  \"Seviper\",\n",
    "  \"Zangoose\",\n",
    "  \"Volbeat\",\n",
    "  \"Illumise\",\n",
    "  \"Kyogre\",\n",
    "  \"Groudon\",\n",
    "  \"Rayquaza\",\n",
    "  \"Chimecho\",\n",
    "  \"Deoxys\",\n",
    "  \"Deoxys-Attack\",\n",
    "  \"Deoxys-Defense\",\n",
    "  \"Deoxys-Speed,Bidoof\",\n",
    "  \"Bibarel\",\n",
    "  \"Kricketot\",\n",
    "  \"Kricketune\",\n",
    "  \"Burmy\",\n",
    "  \"Wormadam\",\n",
    "  \"Wormadam-Sandy-Cloak\",\n",
    "  \"Wormadam-Trash-Cloak\",\n",
    "  \"Mothim\",\n",
    "  \"Pachirisu\",\n",
    "  \"Cherubi\",\n",
    "  \"Cherrim\",\n",
    "  \"Mismagius\",\n",
    "  \"Glameow\",\n",
    "  \"Purugly\",\n",
    "  \"Chingling\",\n",
    "  \"Bronzor\",\n",
    "  \"Bronzong\",\n",
    "  \"Mime Jr.\",\n",
    "  \"Happiny\",\n",
    "  \"Chatot\",\n",
    "  \"Munchlax\",\n",
    "  \"Hippopotas\",\n",
    "  \"Hippowdon\",\n",
    "  \"Mantyke\",\n",
    "  \"Lickilicky\",\n",
    "  \"Tangrowth\",\n",
    "  \"Leafeon\",\n",
    "  \"Glaceon\",\n",
    "  \"Dusknoir\",\n",
    "  \"Rotom\",\n",
    "  \"Uxie\",\n",
    "  \"Mesprit\",\n",
    "  \"Azelf\",\n",
    "  \"Dialga\",\n",
    "  \"Palkia\",\n",
    "  \"Heatran\",\n",
    "  \"Regigigas\",\n",
    "  \"Giratina\",\n",
    "  \"Phione\",\n",
    "  \"Manaphy\",\n",
    "  \"Darkrai\",\n",
    "  \"Shaymin\",\n",
    "  \"Arceus,Patrat\",\n",
    "  \"Watchog\",\n",
    "  \"Purrloin\",\n",
    "  \"Liepard\",\n",
    "  \"Pansage\",\n",
    "  \"Simisage\",\n",
    "  \"Pansear\",\n",
    "  \"Simisear\",\n",
    "  \"Panpour\",\n",
    "  \"Simipour\",\n",
    "  \"Pidove\",\n",
    "  \"Tranquill\",\n",
    "  \"Unfezant\",\n",
    "  \"Blitzle\",\n",
    "  \"Zebstrika\",\n",
    "  \"Woobat\",\n",
    "  \"Swoobat\",\n",
    "  \"Sewaddle\",\n",
    "  \"Swadloon\",\n",
    "  \"Leavanny\",\n",
    "  \"Cottonee\",\n",
    "  \"Whimsicott\",\n",
    "  \"Darumaka\",\n",
    "  \"Darmanitan\",\n",
    "  \"Scraggy\",\n",
    "  \"Scrafty\",\n",
    "  \"Yamask\",\n",
    "  \"Cofagrigus\",\n",
    "  \"Trubbish\",\n",
    "  \"Garbodor\",\n",
    "  \"Minccino\",\n",
    "  \"Cinccino\",\n",
    "  \"Gothita\",\n",
    "  \"Gothorita\",\n",
    "  \"Gothitelle\",\n",
    "  \"Ducklett\",\n",
    "  \"Swanna\",\n",
    "  \"Vanillite\",\n",
    "  \"Vanillish\",\n",
    "  \"Vanilluxe\",\n",
    "  \"Emolga\",\n",
    "  \"Alomomola\",\n",
    "  \"Klink\",\n",
    "  \"Klang\",\n",
    "  \"Klinklang\",\n",
    "  \"Elgyem\",\n",
    "  \"Beheeyem\",\n",
    "  \"Axew\",\n",
    "  \"Fraxure\",\n",
    "  \"Haxorus\",\n",
    "  \"Cubchoo\",\n",
    "  \"Beartic\",\n",
    "  \"Golett\",\n",
    "  \"Golurk\",\n",
    "  \"Pawniard\",\n",
    "  \"Bisharp\",\n",
    "  \"Bouffalant\",\n",
    "  \"Rufflet\",\n",
    "  \"Braviary\",\n",
    "  \"Vullaby\",\n",
    "  \"Mandibuzz\",\n",
    "  \"Heatmor\",\n",
    "  \"Cobalion\",\n",
    "  \"Terrakion\",\n",
    "  \"Virizion\",\n",
    "  \"Reshiram\",\n",
    "  \"Zekrom\",\n",
    "  \"Kyurem\",\n",
    "  \"Kyurem-White\",\n",
    "  \"Kyurem-Black\",\n",
    "  \"Keldeo\",\n",
    "  \"Meloetta\",\n",
    "  \"Genesect,Floette-Eternal-Flower\",\n",
    "  \"Skiddo\",\n",
    "  \"Gogoat\",\n",
    "  \"Furfrou\",\n",
    "  \"Espurr\",\n",
    "  \"Meowstic\",\n",
    "  \"Honedge\",\n",
    "  \"Doublade\",\n",
    "  \"Aegislash\",\n",
    "  \"Spritzee\",\n",
    "  \"Aromatisse\",\n",
    "  \"Swirlix\",\n",
    "  \"Slurpuff\",\n",
    "  \"Inkay\",\n",
    "  \"Malamar\",\n",
    "  \"Binacle\",\n",
    "  \"Barbaracle\",\n",
    "  \"Helioptile\",\n",
    "  \"Heliolisk\",\n",
    "  \"Sylveon\",\n",
    "  \"Dedenne\",\n",
    "  \"Carbink\",\n",
    "  \"Klefki\",\n",
    "  \"Xerneas\",\n",
    "  \"Yveltal\",\n",
    "  \"Zygarde\",\n",
    "  \"Diancie\",\n",
    "  \"Hoopa\",\n",
    "  \"Volcanion,Pikipek\",\n",
    "  \"Trumbeak\",\n",
    "  \"Toucannon\",\n",
    "  \"Yungoos\",\n",
    "  \"Gumshoos\",\n",
    "  \"Grubbin\",\n",
    "  \"Charjabug\",\n",
    "  \"Vikavolt\",\n",
    "  \"Crabrawler\",\n",
    "  \"Crabominable\",\n",
    "  \"Oricorio\",\n",
    "  \"Wishiwashi\",\n",
    "  \"Mareanie\",\n",
    "  \"Toxapex\",\n",
    "  \"Fomantis\",\n",
    "  \"Lurantis\",\n",
    "  \"Oranguru\",\n",
    "  \"Passimian\",\n",
    "  \"Sandygast\",\n",
    "  \"Palossand\",\n",
    "  \"Pyukumuku\",\n",
    "  \"Type-Null\",\n",
    "  \"Silvally\",\n",
    "  \"Minior\",\n",
    "  \"Komala\",\n",
    "  \"Mimikyu\",\n",
    "  \"Drampa\",\n",
    "  \"Tapu Koko\",\n",
    "  \"Tapu Lele\",\n",
    "  \"Tapu Bulu\",\n",
    "  \"Tapu Fini\",\n",
    "  \"Cosmog\",\n",
    "  \"Cosmoem\",\n",
    "  \"Solgaleo\",\n",
    "  \"Lunala\",\n",
    "  \"Nihilego\",\n",
    "  \"Buzzwole\",\n",
    "  \"Pheromosa\",\n",
    "  \"Xurkitree\",\n",
    "  \"Celesteela\",\n",
    "  \"Kartana\",\n",
    "  \"Guzzlord\",\n",
    "  \"Necrozma\",\n",
    "  \"Magearna\",\n",
    "  \"Marshadow\",\n",
    "  \"Poipole\",\n",
    "  \"Naganadel\",\n",
    "  \"Stakataka\",\n",
    "  \"Blacephalon\",\n",
    "  \"Zeraora\",\n",
    "  \"Meltan\",\n",
    "  \"Melmetal\",\n",
    "  \"Rattata-Alolan\",\n",
    "  \"Raticate-Alolan\",\n",
    "  \"Vulpix-Alolan\",\n",
    "  \"Ninetales-Alolan\",\n",
    "  \"Diglett-Alolan\",\n",
    "  \"Dugtrio-Alolan\",\n",
    "  \"Meowth-Alolan\",\n",
    "  \"Persian-Alolan\",\n",
    "  \"Marowak-Alolan,Skwovet\",\n",
    "  \"Greedent\",\n",
    "  \"Nickit\",\n",
    "  \"Thievul\",\n",
    "  \"Wooloo\",\n",
    "  \"Dubwool\",\n",
    "  \"Rolycoly\",\n",
    "  \"Carkol\",\n",
    "  \"Coalossal\",\n",
    "  \"Applin\",\n",
    "  \"Flapple\",\n",
    "  \"Appletun\",\n",
    "  \"Silicobra\",\n",
    "  \"Sandaconda\",\n",
    "  \"Cramorant\",\n",
    "  \"Clobbopus\",\n",
    "  \"Grapploct\",\n",
    "  \"Sinistea\",\n",
    "  \"Polteageist\",\n",
    "  \"Runerigus\",\n",
    "  \"Milcery\",\n",
    "  \"Alcremie\",\n",
    "  \"Falinks\",\n",
    "  \"Pincurchin\",\n",
    "  \"Snom\",\n",
    "  \"Frosmoth\",\n",
    "  \"Stonjourner\",\n",
    "  \"Eiscue\",\n",
    "  \"Indeedee\",\n",
    "  \"Morpeko\",\n",
    "  \"Dracozolt\",\n",
    "  \"Arctozolt\",\n",
    "  \"Dracovish\",\n",
    "  \"Arctovish\",\n",
    "  \"Duraludon\",\n",
    "  \"Zacian\",\n",
    "  \"Zamazenta\",\n",
    "  \"Eternatus\",\n",
    "  \"Zarude\",\n",
    "  \"Regieleki\",\n",
    "  \"Regidrago\",\n",
    "  \"Glastrier\",\n",
    "  \"Spectrier\",\n",
    "  \"Calyrex\",\n",
    "  \"Calyrex-Ice-Rider\",\n",
    "  \"Calyrex-Shadow-Rider\",\n",
    "  \"Ponyta-Galarian\",\n",
    "  \"Rapidash-Galarian\",\n",
    "  \"Slowpoke-Galarian\",\n",
    "  \"Slowbro-Galarian\",\n",
    "  \"Slowking-Galarian\",\n",
    "  \"Mr. Mime-Galarian\",\n",
    "  \"Mr. Rime\",\n",
    "  \"Articuno-Galarian\",\n",
    "  \"Zapdos-Galarian\",\n",
    "  \"Moltres-Galarian\",\n",
    "  \"Corsola-Galarian\",\n",
    "  \"Cursola\",\n",
    "  \"Darumaka-Galarian\",\n",
    "  \"Darmanitan-Galarian\",\n",
    "  \"Yamask-Galarian\",\n",
    "  \"Stunfisk-Galarian\",\n",
    "  \"Braviary-Hisuian\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data file parsing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From Pokemon Showdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_move_data_ps_file(run_bun=False):\n",
    "    with open(os.path.join(get_dir(run_bun), \"moves\", \"move_data_ps.json\")) as file:\n",
    "        all_move_data = json.load(file)\n",
    "    all_move_data = {x['name']: x for x in all_move_data}\n",
    "    with open(\n",
    "        os.path.join(get_dir(False), \"moves\", \"move_universe_raw.json\"), \"r\"\n",
    "    ) as file:\n",
    "        move_universe = json.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From online sources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pokemon data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input files:\n",
    "- `data/base_gen_8/base_stats.csv`\n",
    "  - CSV of Pokemon, types, and stats through Generation 8.\n",
    "  - From [PokemonDB's text list of Pokemon](https://pokemondb.net/tools/text-list), make sure it's comma-separated and ask for all attributes. Filter for \"All Forms.\" Generate the list, then filter for \"Generation 9\" and remove any lines that also appear there.\n",
    "  - Reference [Serebii's list](https://www.serebii.net/scarletviolet/updatedstats.shtml) for Pokemon whose base stats were changed in in Gen 9.\n",
    "\n",
    "Output files:\n",
    "- `data/base_gen_8/species_data_normal.txt`\n",
    "- `data/base_gen_8/species_data_form.txt`\n",
    "- `data/base_gen_8/pkmn_list.txt`\n",
    "\n",
    "I downloaded Pokedex CSV data (dex number, type(s), base stats and for different forms) from PokemonDB. `read_base_stats()` parses it into space-delimited minimal lines to be read by the C++ programs.\n",
    "\n",
    "For now I separate \"normal\" forms from alternate forms -- this is probably wrong since e.g. Lycanroc has no \"normal\" form, just several possible forms. I just wanted the Pokedex number to match the line...but I'll probably have to change this.\n",
    "\n",
    "I also generate the list of species to be copy-pasted into `pokemon_enums.hpp` from this data. In this step, I manually replaced Flabebe with alphanumeric e's and Nidorans with _M, _F in `pkmn_list.txt` after running `read_base_stats()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_base_stats():\n",
    "    DIR = get_dir(False)\n",
    "    with open(os.path.join(DIR, \"base_stats.csv\"), \"r\") as file_stats:\n",
    "        with open(os.path.join(DIR, \"species_data_normal.txt\"), \"w\") as file_norm:\n",
    "            with open(os.path.join(DIR, \"species_data_form.txt\"), \"w\") as file_form:\n",
    "                reader = csv.DictReader(file_stats)  # Reading as a list\n",
    "                for row in reader:\n",
    "                    res = \" \".join(\n",
    "                        [\n",
    "                            row[\"HP\"],\n",
    "                            row[\"Attack\"],\n",
    "                            row[\"Defense\"],\n",
    "                            row[\"Sp.Attack\"],\n",
    "                            row[\"Sp.Defense\"],\n",
    "                            row[\"Speed\"],\n",
    "                            str(ALL_TYPES.index(row['Type 1'].upper())),\n",
    "                            str(ALL_TYPES.index(row['Type 2'].upper()))\n",
    "                        ]\n",
    "                    )\n",
    "                    if row[\"Form\"]:\n",
    "                        file_form.write(f\"{row['Form']} {res}\\n\")\n",
    "                    else:\n",
    "                        file_norm.write(f\"{res}\\n\")\n",
    "    # Generating list of values for Species enum\n",
    "    list_of_species = []\n",
    "    with open(os.path.join(DIR, \"base_stats.csv\"), \"r\") as file:\n",
    "        reader = csv.DictReader(file)  # Reading as a list\n",
    "        for row in reader:\n",
    "            if not row[\"Form\"]:\n",
    "                list_of_species.append(\n",
    "                    row[\"Name\"]\n",
    "                    .upper()\n",
    "                    .replace(\". \", \"_\")\n",
    "                    .replace(\": \", \"_\")\n",
    "                    .replace(\" \", \"_\")\n",
    "                    .replace(\".\", \"\")\n",
    "                    .replace(\"-\", \"_\")\n",
    "                    .replace(\"'\", \"\")\n",
    "                )\n",
    "    with open(os.path.join(DIR, \"pkmn_list.txt\"), \"w\") as file:\n",
    "        # NOTE: manual changes needed!\n",
    "        for species in list_of_species:\n",
    "            file.write(f\"{species},\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trainer battle data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input files:\n",
    "- `data/run_and_bun/trainer_battles.txt`\n",
    "  - From [Run and Bun documentation](https://drive.google.com/drive/folders/1M-PdZrACBkGPpceTanCq_ltbGNT24lR8) `Trainer_Battles.txt`.\n",
    "  - I had to do some cleaning with regex to the raw info from `Trainer_Battles.txt` found in Run and Bun documentation. This is useful since it gives me the actual universe of possible enemy trainers, telling me Dyna/Gigamax isn't in the game and Z-moves aren't either. It also gave me indications (by comparing set of moves to PokemonDB) as to moves I had to make a consistent name for, and reminded me about the special case of Hidden Power (I'll need to swap existing move data for the different-typed versions of it).\n",
    "\n",
    "Output files:\n",
    "- `data/run_and_bun/trainer_battles.json`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_trainer_battles_data():\n",
    "    def parse_moveset(moveset):\n",
    "        pattern = re.compile(\n",
    "            r\"(?P<species>[A-Za-z\\d_]+)\\s+Lv\\.(?P<lvl>\\d+)\\s+\"\n",
    "            r\"(@(?P<item>[A-Za-z\\s]+):\\s*)?\"\n",
    "            r\"(?P<moves>[^\\[]*)\\s*\"\n",
    "            r\"\\[(?P<nature>[^|]+)\\|(?P<ability>[^]]+)\\]\"\n",
    "        )\n",
    "        # print(pattern.search(\"\"\"Kirlia Lv.43 [Modest|Synchronize]\"\"\").groupdict())\n",
    "        match = pattern.search(moveset)\n",
    "        if not match:\n",
    "            return None\n",
    "        data = match.groupdict()\n",
    "        data[\"moves\"] = data[\"moves\"].strip()\n",
    "        data[\"moves\"] = data[\"moves\"].split(\", \") if data[\"moves\"] else []\n",
    "        return data\n",
    "\n",
    "    DIR = get_dir(True)\n",
    "\n",
    "    trainers = []\n",
    "    with open(os.path.join(DIR, \"trainer_battles.txt\")) as file:\n",
    "        next_line = file.readline().strip()\n",
    "        while next_line:\n",
    "            new_trainer = {\"name\": next_line, \"team\": []}\n",
    "            next_line = file.readline().strip()\n",
    "            while next_line:\n",
    "                new_trainer[\"team\"].append(parse_moveset(next_line))\n",
    "                next_line = file.readline().strip()\n",
    "            trainers.append(new_trainer)\n",
    "            next_line = file.readline().strip()\n",
    "        with open(os.path.join(DIR, \"trainer_battles.json\"), \"w\") as jf:\n",
    "            json.dump(trainers, jf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Move data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parse moves through Gen 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input files:\n",
    "- `data/base_gen_8/all_moves_through_gen_9.txt`\n",
    "  - HTML-formatted list of moves.\n",
    "  - From [PokemonDB's list of moves](https://pokemondb.net/move/all). Unlike Pokedex, there's no convenient download option, so I copy-pasted the table source code they have (for all-through-gen-9 moves since there's limited sorting) and use regex to parse through the HTML. A lot of adjustment was needed to eliminate unintended Nones from special cases...\n",
    "\n",
    "Output files:\n",
    "- `data/base_gen_8/all_moves_through_gen_9.json`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_move_data():\n",
    "    def parse_move(html):\n",
    "        pattern = re.compile(\n",
    "            r'<td class=\"cell-name\"><a .* title=\"View details for (?P<move>[^\"]+)\">.*</a></td>'\n",
    "            r' ?<td class=\"cell-icon\"><a .*>(?P<type>[^<]+)</a></td>'\n",
    "            r' ?<td class=\"cell-icon text-center\".*data-sort-value=\"(?P<kind>[^\"]*)\".*</td>'\n",
    "            r' ?<td class=\"cell-num\">(?P<power>\\d+|-)</td>'\n",
    "            r' ?<td class=\"cell-num[^>]*>(?P<accuracy>\\d+|-|&infin;)</td>'\n",
    "            r' ?<td class=\"cell-num\" ?>(?P<pp>\\d+|-)</td>'\n",
    "            r' ?<td class=\"cell-long-text\" ?>(?P<desc>[^<]*)</td>'\n",
    "            r' ?<td class=\"cell-num\" ?>(?P<prob>\\d+|-)</td>'\n",
    "        )\n",
    "        match = pattern.search(html)\n",
    "        if not match:\n",
    "            return None\n",
    "        data = match.groupdict()\n",
    "        for key in [\"power\", \"accuracy\", \"pp\", \"prob\"]:\n",
    "            if data[key] == \"-\":\n",
    "                data[key] = None\n",
    "            elif data[key] == \"&infin;\":\n",
    "                data[key] = \"Infinity\"\n",
    "            else:\n",
    "                data[key] = int(data[key])\n",
    "        return data\n",
    "\n",
    "    DIR = get_dir(False)\n",
    "    moves = []\n",
    "    with open(os.path.join(DIR, \"moves\", \"all_moves_through_gen_9.txt\")) as file:\n",
    "        next_line = file.readline().strip()\n",
    "        while next_line:\n",
    "            moves.append(\n",
    "                parse_move(\n",
    "                    next_line + file.readline().strip() + file.readline().strip()\n",
    "                )\n",
    "            )\n",
    "            next_line = file.readline().strip()\n",
    "        with open(\n",
    "            os.path.join(DIR, \"moves\", \"all_moves_through_gen_9.json\"), \"w\"\n",
    "        ) as jf:\n",
    "            json.dump(moves, jf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run and Bun move changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_move_data(run_bun=False):\n",
    "    # Documentation on Run and Bun version of data: https://docs.google.com/spreadsheets/d/1CgGbps15g9EHtrtXzNsJ7_p6oqvqYSuMd0lKeIk36Og/edit?gid=1689048578#gid=1689048578\n",
    "    with open(os.path.join(get_dir(True), \"moves\", \"move_changes.csv\")) as file:\n",
    "        reader = csv.DictReader(file)\n",
    "        move_changes = {row[\"Move\"].upper(): row for row in reader}\n",
    "    conversion = {\n",
    "        \"BP\": \"power\",\n",
    "        \"PP\": \"pp\",\n",
    "        \"Accuracy\": \"accuracy\",\n",
    "        \"Effect Chance\": \"prob\",\n",
    "    }\n",
    "\n",
    "    def update_move(run_bun, move, move_data):\n",
    "        if run_bun:\n",
    "            move = move.upper()\n",
    "            if move in move_changes:\n",
    "                changes = move_changes[move]\n",
    "                for field in [\"BP\", \"PP\", \"Accuracy\", \"Effect Chance\", \"Type\"]:\n",
    "                    if changes[field] != \"None\":\n",
    "                        old, new = changes[field].split(\" > \")\n",
    "                        if field in [\"Accuracy\", \"Effect Chance\"]:\n",
    "                            old, new = old[:-1], new[:-1]  # Get rid of %\n",
    "                        if field == \"Type\":\n",
    "                            assert move_data[\"type\"] == old\n",
    "                            move_data[\"type\"] = new\n",
    "                        else:\n",
    "                            if (move, field) not in [\n",
    "                                (\"FRUSTRATION\", \"BP\"),\n",
    "                                (\"RETURN\", \"BP\"),\n",
    "                                (\"SCREECH\", \"PP\"),\n",
    "                                (\"HARDEN\", \"PP\"),\n",
    "                                (\"ROOST\", \"PP\"),\n",
    "                            ]:\n",
    "                                assert move_data[conversion[field]] == int(\n",
    "                                    old\n",
    "                                ), f\"{move} {field} {move_data[conversion[field]]} {int(old)}\"\n",
    "                            move_data[conversion[field]] = int(new)\n",
    "        return move_data\n",
    "\n",
    "    moves = set()\n",
    "    with open(\n",
    "        os.path.join(get_dir(False), \"moves\", \"all_moves_through_gen_9.json\")\n",
    "    ) as file:\n",
    "        m = json.load(file)\n",
    "        for move in m:\n",
    "            moves.add(move[\"move\"].strip())\n",
    "    with open(os.path.join(get_dir(False), \"moves\", \"all_moves_gen_9.json\")) as file:\n",
    "        m = json.load(file)\n",
    "        for move in m:\n",
    "            moves.remove(move.strip())\n",
    "    ret = {}\n",
    "    with open(\n",
    "        os.path.join(get_dir(False), \"moves\", \"all_moves_through_gen_9.json\")\n",
    "    ) as file:\n",
    "        m = json.load(file)\n",
    "        m = {x[\"move\"]: x for x in m}\n",
    "        for move in moves:\n",
    "            ret[move] = update_move(run_bun, move, m[move])\n",
    "        with open(os.path.join(get_dir(run_bun), \"moves\", \"move_data.json\"), \"w\") as of:\n",
    "            json.dump(ret, of)\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find move universe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We sanity-check that the set of all moves found in trainer battles is a subset of all moves through gen 8 and that Max moves and Z-moves are not included in the game. We also find the universe of moves we may have to implement (i.e. non-Max or Z through Gen 8), and count the number of moves of each type.\n",
    "- G-Max moves: 33\n",
    "- Max moves: 19\n",
    "- Z-moves: 35\n",
    "- Regular moves: 818\n",
    "- of which 475 are found in opponent movesets.\n",
    "\n",
    "Input files: \n",
    "- `data/moves/move_data.json`\n",
    "- `data/moves/trainer_battles.json`\n",
    "\n",
    "Output files:\n",
    "- `data/moves/move_universe_raw.json`\n",
    "  - asdf\n",
    "- `data/moves/move_universe_formatted.txt`\n",
    "  - List of moves to be copy-pasted into `pokemon_enums.hpp`\n",
    "  - After running code, manually replace SING with SING_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_move_universe():\n",
    "    with open(os.path.join(get_dir(False), \"moves\", \"move_data.json\")) as file:\n",
    "        move_data = json.load(file)\n",
    "    moves = list(move_data.keys())\n",
    "    trainer_moves = set()\n",
    "    DIR = get_dir(True)\n",
    "    with open(os.path.join(DIR, \"trainer_battles.json\")) as file:\n",
    "        t = json.load(file)\n",
    "        for trainer in t:\n",
    "            for pkmn in trainer[\"team\"]:\n",
    "                for move in pkmn[\"moves\"]:\n",
    "                    trainer_moves.add(move.strip())\n",
    "    g_max_moves = []\n",
    "    max_moves = []\n",
    "    z_moves = [\n",
    "        \"Breakneck Blitz\",\n",
    "        \"All-Out Pummeling\",\n",
    "        \"Supersonic Skystrike\",\n",
    "        \"Acid Downpour\",\n",
    "        \"Tectonic Rage\",\n",
    "        \"Continental Crush\",\n",
    "        \"Savage Spin-Out\",\n",
    "        \"Never-Ending Nightmare\",\n",
    "        \"Corkscrew Crash\",\n",
    "        \"Inferno Overdrive\",\n",
    "        \"Hydro Vortex\",\n",
    "        \"Bloom Doom\",\n",
    "        \"Gigavolt Havoc\",\n",
    "        \"Shattered Psyche\",\n",
    "        \"Subzero Slammer\",\n",
    "        \"Devastating Drake\",\n",
    "        \"Black Hole Eclipse\",\n",
    "        \"Twinkle Tackle\",\n",
    "        \"Catastropika\",\n",
    "        \"10,000,000 Volt Thunderbolt\",\n",
    "        \"Stoked Sparksurfer\",\n",
    "        \"Extreme Evoboost\",\n",
    "        \"Pulverizing Pancake\",\n",
    "        \"Genesis Supernova\",\n",
    "        \"Sinister Arrow Raid\",\n",
    "        \"Malicious Moonsault\",\n",
    "        \"Oceanic Operetta\",\n",
    "        \"Splintered Stormshards\",\n",
    "        \"Let's Snuggle Forever\",\n",
    "        \"Clangorous Soulblaze\",\n",
    "        \"Guardian of Alola\",\n",
    "        \"Searing Sunraze Smash\",\n",
    "        \"Menacing Moonraze Maelstrom\",\n",
    "        \"Light That Burns the Sky\",\n",
    "        \"Soul-Stealing 7-Star Strike\",\n",
    "    ]\n",
    "    normal_moves = []\n",
    "    for m in moves:\n",
    "        if \"G-Max\" in m:\n",
    "            g_max_moves.append(m)\n",
    "        elif \"Max\" in m:\n",
    "            max_moves.append(m)\n",
    "        elif m not in z_moves:\n",
    "            if m == \"Hidden Power\":  # Hidden power special case\n",
    "                for typ in ALL_TYPES:\n",
    "                    if typ:\n",
    "                      normal_moves.append(f\"{m}_{typ}\")\n",
    "            else:\n",
    "                normal_moves.append(m)\n",
    "    return sorted(normal_moves)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_move_universe():\n",
    "    move_universe = (\n",
    "        generate_move_universe()\n",
    "    )  # Don't read data! This is how we generate the easier-to-read file\n",
    "    DIR = get_dir(False)\n",
    "    with open(os.path.join(DIR, \"moves\", \"move_universe_raw.json\"), \"w\") as file:\n",
    "        json.dump(move_universe, file)\n",
    "    with open(os.path.join(DIR, \"moves\", \"move_universe_formatted.txt\"), \"w\") as file:\n",
    "        for move in move_universe:\n",
    "            move = move.replace(\" \", \"_\").replace(\"-\", \"_\").replace(\"'\", \"\").upper()\n",
    "            file.write(f\"{move},\")  # Manually replace SING with SING_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate C++ move data input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input files:\n",
    "- `data/moves/move_data.json`\n",
    "- `data/moves/move_universe_raw.json`\n",
    "\n",
    "Output files:\n",
    "- `data/moves/move_data.txt`\n",
    "  - Move data as space-delimited minimal lines to be read by the C++ programs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_move_data_file(run_bun=False):\n",
    "    # Generated file orders moves in same order as in move_universe (so it should match with enum)\n",
    "    with open(os.path.join(get_dir(run_bun), \"moves\", \"move_data.json\")) as file:\n",
    "        move_data = json.load(file)\n",
    "    # We can read what we just generated, here\n",
    "    with open(\n",
    "        os.path.join(get_dir(False), \"moves\", \"move_universe_raw.json\"), \"r\"\n",
    "    ) as file:\n",
    "        move_universe = json.load(file)\n",
    "    with open(os.path.join(get_dir(run_bun), \"moves\", \"move_data.txt\"), \"w\") as file:\n",
    "        hp = \"Hidden Power\"\n",
    "        for move in move_universe:\n",
    "            ref_move = hp if hp in move else move\n",
    "            data = move_data[ref_move]\n",
    "            # Hidden Power special case\n",
    "            typ = ALL_TYPES.index(\n",
    "                move.split(\"_\")[-1] if hp in move else data[\"type\"].upper()\n",
    "            )\n",
    "            kind = ALL_MOVE_KINDS.index(data[\"kind\"].upper())\n",
    "            # Not sure if this decrease in info works:\n",
    "            pow = -1 if data[\"power\"] is None else data[\"power\"]\n",
    "            acc = -1 if data[\"accuracy\"] in [None, \"Infinity\"] else data[\"accuracy\"]\n",
    "            pp = -1 if data[\"pp\"] is None else data[\"pp\"]\n",
    "            prob = -1 if data[\"prob\"] is None else data[\"prob\"]\n",
    "            file.write(f\"{typ} {kind} {pow} {acc} {pp} {prob}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Misc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Roughly count the set of Pokemon that aren't in Run and Bun at all:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(get_dir(True), \"trainer_battles.json\")) as jf:\n",
    "    trainers = json.load(jf)\n",
    "    enemy_pkmn = set()\n",
    "    for trainer in trainers:\n",
    "        for pkmn in trainer['team']:\n",
    "            enemy_pkmn.add(pkmn['species'])\n",
    "    print(len(set(UNAVAILABLE_PKMN) - enemy_pkmn))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
